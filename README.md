# Illegal-Logging-Detector-Infineon

<img src="./Images/logo.png" width="100%">

# Introduction:

Avoid illegal logging in protected areas.

We can find that just in Mexico (my home country) [1] 70 percent of the wood consumed is of illegal origin according to a study carried out by one of the most prestigious universities UNAM (QS ranking # 94 - 2025).

https://translate.google.com/translate?sl=es&tl=en&u=https://www.dgcs.unam.mx/boletin/bdboletin/2018_173.html

<img src="./Images/treeee.jpg">

I’ll  create a system that is capable of recognizing, through Machine Learning the sounds generated by falling trees, chainsaws and human voices in protected areas, thus warning that illegal logging may be occurring.

I especially want a system that can help protect forests and the species that inhabit them.

<img src="./Images/fores (1).jpg" height="200" ><img src="./Images/fores (2).jpg" height="200" >

Most solutions are based on raising awareness, but looking at more dedicated solutions we can find:

- TreeTAG is an emerging smartphone-based supply chain traceability system developed by Earth Observation Systems that tracks the location of logs transported from the forest to the mill.

- Disadvantages: Very complex system that requires authorized personnel to be manipulated.

- Stardust is a dust-like material that can be sprayed onto wood and detected only with a hand-held device. 

- Disadvantages: You need to tag manually every tree which is labor intensive and expensive.

# Solution:

The system, will be easily reproducible, energy efficient and powerful thanks to the ML algorithms that will be implemented and trained with the cloud services that we will use for deployment.

<img src="./Images/imagi.webp" width="100%">

With the CY8CKIT-062S2-AI i will obtain an audio signal which, through DEEPCRAFT™ Model, we can pass through a neural network. That will tell us if the noise of a saw cutting the trees or human voice in the forest.

# System:

<img src="./Images/diagram.png" width="100%">

### Features:

* Low-power battery consumption (CY8CKIT-062S2-AI).
* High accuracy (Thanks to DEEPCRAFT™).
* Easy production at large scale, due to its simplicity.

### Hardware:

* CY8CKIT-062S2-AI. 1x.
  * https://www.infineon.com/cms/en/product/evaluation-boards/cy8ckit-062s2-ai/
* RGB Led 1x. 
  * https://www.amazon.com/Tri-Color-Multicolor-Difundido-Resistencias-Incluido/dp/B077XGF3YR/?th=1
* 100 Ohms Resistor 3x. 
  * https://www.amazon.com/EDGELEC-resistencias-tolerancia-m%C3%BAltiples-resistencia/dp/B07QG1VL1Q
* Buzzer 1x. 
  * https://www.amazon.com/DC-electr%C3%B3nico-zumbador-vivienda-conector/dp/B0DHRMYHQ2

### Software:

* DEEPCRAFT™.
  * https://www.imagimob.com/
* ModusToolbox™.
  * https://www.infineon.com/cms/en/design-support/tools/sdk/modustoolbox-software/
* Audacity.
  * https://www.audacityteam.org/

# Capturing Data:

La calidad de un modelo de AI depende mucho de los datos con los que se entrene,  en mi caso estoy buscando 3 detecciones principales.

- Chainsaw: Detectar si hay ruido de chainsaw que vayan a cortar un arbol.
- People: La deteccion de voz humana, para detectar presenciq humana cerca del area.
- Forest: este seria el ruido de un bosque, este seria el estado base del sistema ya que en el bosque no suele haber silencio absoluto.
 
Ahora explicare un poco los detalles de los datos y el porque de la distribucion.

| Category  | Number of DataFrames | Duration per DataFrame |
|-----------|---------------------|------------------------|
| Chainsaw  | 13                  | 1 min each            |
| Forest    | 13                  | 1 min each            |
| People    | 13                  | 1 min each            |

Esta distribucion de 13 archivos de audio de una duracion de 1 min cada uno, tiene el fin de facilitar a DEEPCRAFT™ la division y el entrenamiento del modelo con los datos.

<img src="./Images/deep1.png" width="100%">

Todos estos datos fueron recortados en Audacity para facilitar la manipulacion del audio, ademas este programa nos permite convertir a Mono el audio y asegurarnos que esta a 16kHz como el input de el microfono en la board.

Todos los dataframes estan en la siguiente liga: [CLICK HERE](./Illegal%20Logging%20Detector%20Model/Data/)

# DEEPCRAFT™:

### Labeling:

Como se menciono en el punto anterior las bases de datos estan distribuidas de forma que DEEPCRAFT™ sea capaz de ideintificar cada uno de los dataframes como segmentos diferentes.

<img src="./Images/deep2.png" width="100%">

Las prediction labels que vamos a identificar en todos estos audios seran las descritas anteriormente.

<img src="./Images/deep3.png" width="100%">

### Distribute:

Una vez realizado el labeling de todos los audios, podras de forma manual seleccionar a donde va cada uno de los sets, Train, Test or Validation. Sin embargo ya que realizamos segmentos uniformes, podremos hacer la distribucion automatica con el programa.

<img src="./Images/deep4.png" height="300px">

### Preprocessor:

Si todos los pasos anteriores estan correctos podemos pasar a la seccion de Preprocessor, esta seccion es sumamente importante para realizar el modelo ya que tendremos que agregar unos componentes adicionales para que el modelo funcione correctamente en la board.

<img src="./Images/deep5.png" width="100%">

- Imagimob Speech Features: Este componente realizara un preprocesamiento de la señal para poder obtener solo las features relevantes para el modelo, aunque para nuestro proyecto un rango de 300Hz - 8000Hz es suficiente, recomendamos realizar un analisis de espectrograma de tus audios para estar seguro que no pierdes features importantes.

<img src="./Images/deep6.png" height="300px">

- Contextual Window (Sliding Window): Esta capa de preprocesamiento nos permite realizar la tecnica de windowing para procesar los datos en la red neuronal, esta estrategia es ampliamente utilizada en modelos dedicados a IoT y ademas el modelo no permitira compilarlo de no usarla.

<img src="./Images/deep7.png" width="100%">

### Model Selection:

Debido a que vamos a correr el modelo en una board pequeña, lo mejor es tratar que los modelos AI sean los mas pequeños posibles, aunque yo use la siguiente configuracion, puedes experimentar con otras configuraciones.

<img src="./Images/deep8.png" width="100%">

### Model Validation:

Una vez realizado el entrenamiento del modelo de AI obtuvimos los sigientes resultados.

<img src="./Images/deep9.png" height="400px">

Este modelo lo revisamos directamente en el programa con el fin de ver que este dando los resultados correctos.

<img src="./Images/deep10.png" width="100%">

Finalmente los resultados para realizar la deteccion de voz humana fueron correctos.

<img src="./Images/deep11.png" width="100%">

### Generate Code:

Tan solo con el archivo .h5 no es suficiente para ya desplegar el modelo en nuestra board, para ello deberemos de convertir la red neuronal en los archivos model.c y model.h con el formato correcto para que pueda correr en la board, asi que deberas configurar los siguiente parametros  y generar el codigo.

<img src="./Images/deep12.png" width="100%">

# ModusToolbox™

Finalmente con los archivos model.c y model.h, podremos desplegarlo en nuestro device mediante el proyecto de Modus.

<img src="./Images/modus1.png" width="100%">

### Deploy Model:

Recomendamos copiar el proyecto dentro de este repositorio para evitar problemas de compatibilidad, finalmente solo quedaria realizar el build del proyecto y programar nuestra board.

<img src="./Images/modus2.png" width="100%">

Si todos los pasos anteriores los realizaste correctamente, deberas de ver los resultados del modelo directamente en la terminal.

<img src="./Images/modus3.png" width="100%">

Este resultado lo obtenemos al poner un simulador de Chainsaw alado del device, mostrando que esta detectando correctamente la chainsaw.

<img src="./Images/chain.jpg" width="100%">

Posteriormente, para tener una señal de salida una vez se coloque en un árbol, le pusimos una configuración de LED RGB con el fin de visualizar los resultados en tiempo real.

```c
else if(best_label != 0 && max_score >= 0.50)
{
  prev_best_label = best_label;
  printf("Output: %-30s\r\n", label_text[best_label]);
  if(label_text[best_label]=="Chainsaw"){
    turnOnRed();
    turnOnBuzzer();
  }
  else if(label_text[best_label]=="Human"){
    turnOnBlue();
    turnOffBuzzer();
  }
  else if(label_text[best_label]=="Standby" || label_text[best_label]=="unlabelled"){
    turnOnGreen();
    turnOffBuzzer();
  }
}
```

El circuito se ve de esta manera, es muy sencillo pero los valroes de las reisistencias para un buen funcionamiento.

<img src="./Images/rgb.jpg" width="70%">

# Final Product:

Case Closed:

<img src="./Images/case3.jpg">

Case open:

<img src="./Images/case4.jpg">